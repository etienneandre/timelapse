#!/usr/bin/env python3
# -*- coding: utf-8 -*-

# Created      : 2025/11/08
# Last modified: 2025/11/09
# Author       : √âtienne Andr√©
# Disclaimer   : first version obtained as a union of fragments generated by a generative AI chatbot

import os
import sys
import subprocess
import re
import shutil
from datetime import datetime
from PIL import Image, ImageDraw, ImageFont
from PIL.ExifTags import TAGS

import cv2
import numpy as np
import glob #, os
from tqdm import tqdm


VIDEO_NAME = "timelapse.mp4"
FPS = 12


############################################################
# PARTIE 1: renommage
############################################################

# TODO: detect if 2 pictures have the same %Y-%m-%d-%H-%M

def extraire_date_exif(chemin_image):
    """Retourne la date/heure EXIF sous forme de datetime, ou None si introuvable."""
    try:
        with Image.open(chemin_image) as img:
            exif_data = img._getexif()
            if not exif_data:
                return None

            for tag, value in exif_data.items():
                tag_name = TAGS.get(tag, tag)
                if tag_name in ("DateTimeOriginal", "DateTime", "DateTimeDigitized"):
                    try:
                        return datetime.strptime(value, "%Y:%m:%d %H:%M:%S")
                    except Exception:
                        return None
        return None
    except Exception:
        return None


def main_renommage(repertoire_entree, repertoire_sortie):
    # Extensions d‚Äôimages prises en charge
    extensions_valides = {".jpg", ".jpeg", ".png", ".tiff", ".bmp", ".heic", ".webp"}

    nb_ok = 0
    nb_erreurs = 0

    for nom_fichier in os.listdir(repertoire_entree):
        chemin_entree = os.path.join(repertoire_entree, nom_fichier)

        if not os.path.isfile(chemin_entree):
            continue

        _, ext = os.path.splitext(nom_fichier)
        if ext.lower() not in extensions_valides:
            continue

        date_exif = extraire_date_exif(chemin_entree)

        if date_exif:
            nouveau_nom = f"{prefixe}-{date_exif.strftime('%Y-%m-%d-%H-%M')}{ext.lower()}"
            nb_ok += 1
            chemin_sortie = os.path.join(repertoire_sortie, nouveau_nom)
            # TODO: √©ventuellement v√©rifier ici que le fichier n'existe pas d√©j√†, auquel cas, le renum√©roter
            shutil.copy2(chemin_entree, chemin_sortie)

        else:
            print(f"‚ö†Ô∏è Erreur: pas de donn√©es EXIF valides pour '{nom_fichier}'")
            # NOTE: finalement, on ne copie pas le fichier, oust
            # nouveau_nom = f"erreur-{nom_fichier}"
            nb_erreurs += 1


    print("\n=== R√©sum√© ===")
    print(f"Images converties correctement : {nb_ok}")
    print(f"Images en erreur               : {nb_erreurs}")
    print(f"Fichiers enregistr√©s dans      : {repertoire_sortie}")



# # === R√©glages ===
# MAX_FEATURES = 5000
# RATIO_TEST = 0.75       # ratio pour knnMatch
# MIN_MATCH_COUNT = 8     # nombre minimal de correspondances fiables pour homographie
# N_AVG = 20   # nombre d‚Äôimages utilis√©es pour calculer la moyenne
#
# ############################################################
# # VERSION 1
#
# def align_images_old(im, im_ref):
#     """
#     Aligne im sur im_ref.
#     Retourne (im_aligned, H) o√π H est la transformation (3x3) appliqu√©e √† im.
#     Si √©chec, renvoie im (non modifi√©e) et la matrice identit√©.
#     """
#     im1_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
#     im2_gray = cv2.cvtColor(im_ref, cv2.COLOR_BGR2GRAY)
#
#     # D√©tecteur / descripteur ORB
#     orb = cv2.ORB_create(MAX_FEATURES)
#     kp1, des1 = orb.detectAndCompute(im1_gray, None)
#     kp2, des2 = orb.detectAndCompute(im2_gray, None)
#
#     # Si pas de descripteurs, on renvoie l'image d'origine
#     if des1 is None or des2 is None or len(kp1) < 4 or len(kp2) < 4:
#         H = np.eye(3, dtype=np.float32)
#         return im.copy(), H
#
#     # Matcher BF Hamming (pour ORB)
#     bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)
#
#     # knnMatch + ratio test
#     knn_matches = bf.knnMatch(des1, des2, k=2)
#     good_matches = []
#     for m_n in knn_matches:
#         if len(m_n) != 2:
#             continue
#         m, n = m_n
#         if m.distance < RATIO_TEST * n.distance:
#             good_matches.append(m)
#
#     if len(good_matches) >= MIN_MATCH_COUNT:
#         # Extraire points
#         pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])
#         pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])
#
#         # Homographie robuste
#         H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)
#         if H is not None:
#             h, w = im_ref.shape[:2]
#             im1_reg = cv2.warpPerspective(im, H, (w, h))
#             return im1_reg, H
#
#     # Si pas assez de bonnes correspondances pour homographie, essayer une transformation affine partielle
#     # On retente en utilisant estimation affine sur toutes les bonnes matches (m√™me si moins)
#     if len(good_matches) >= 4:
#         pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])
#         pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])
#         M, inliers = cv2.estimateAffinePartial2D(pts1, pts2, method=cv2.RANSAC)
#         if M is not None:
#             # convertir affine 2x3 en 3x3
#             H_aff = np.vstack([M, [0,0,1]])
#             h, w = im_ref.shape[:2]
#             im1_reg = cv2.warpAffine(im, M, (w, h))
#             return im1_reg, H_aff
#
#     # Sinon fallback: renvoyer image inchang√©e et identit√©
#     return im.copy(), np.eye(3, dtype=np.float32)
#
# # === Traitement ===
# def main_alignement_old():
#     IMG_DIR = repertoire_sortie
#     OUTPUT_DIR = IMG_DIR + "-alignes"
#
#     os.makedirs(OUTPUT_DIR, exist_ok=True)
#
#     files = sorted(glob.glob(os.path.join(IMG_DIR, "*.jpg")))
#     if not files:
#         raise SystemExit("Aucune image trouv√©e dans " + IMG_DIR)
#
#
#     print(f"[INFO] Alignement de {len(files)} images‚Ä¶")
#     ref = cv2.imread(files[0])
#     aligned_images = [(files[0], ref)]
#
#     for f in tqdm(files[1:], desc="Alignement"):
#         im = cv2.imread(f)
#         aligned, _ = align_images_old(im, ref)
#         aligned_images.append((f, aligned))
#
#     # # Calcul du recadrage commun (utiliser logical_and.reduce pour robustesse)
#     # print("[INFO] Calcul du cadrage commun‚Ä¶")
#     # masks = [(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) > 0) for img in aligned_images]
#     # common_mask = np.logical_and.reduce(masks).astype(np.uint8)
#     # ys, xs = np.where(common_mask)
#     # if ys.size == 0 or xs.size == 0:
#     #     raise SystemExit("Intersection vide ‚Äî les images sont trop d√©cal√©es apr√®s alignement.")
#     # ymin, ymax, xmin, xmax = ys.min(), ys.max(), xs.min(), xs.max()
#
#     # === 4. Calcul du recadrage commun ===
#     print("[INFO] Calcul du cadrage commun (zone non noire)‚Ä¶")
#     masks = [(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) > 0) for _, img in aligned_images]
#     common_mask = np.logical_and.reduce(masks).astype(np.uint8)
#     ys, xs = np.where(common_mask)
#     if ys.size == 0 or xs.size == 0:
#         raise SystemExit("Intersection vide ‚Äî les images sont trop d√©cal√©es apr√®s alignement.")
#     ymin, ymax, xmin, xmax = ys.min(), ys.max(), xs.min(), xs.max()
#
#     # === 5. Sauvegarde des images align√©es ===
#     print("[INFO] Sauvegarde des images align√©es‚Ä¶")
#     for orig_path, img in aligned_images:
#         filename = os.path.basename(orig_path)
#         cropped = img[ymin:ymax+1, xmin:xmax+1]
#         outpath = os.path.join(OUTPUT_DIR, filename)
#         cv2.imwrite(outpath, cropped)
#
#     # cropped_images = [img[ymin:ymax+1, xmin:xmax+1] for img in aligned_images]
#     #
#     # print("[INFO] Sauvegarde des images align√©es‚Ä¶")
#     # for i, img in enumerate(cropped_images):
#     #     outpath = os.path.join(OUTPUT_DIR, f"frame_{i:04d}.jpg")
#     #     cv2.imwrite(outpath, img)
#
#     # print("[INFO] Cr√©ation de la vid√©o finale avec framerate " + FPS + "‚Ä¶")
#     # os.system(f"ffmpeg -y -framerate {FPS} -i {OUTPUT_DIR}/frame_%04d.jpg -c:v libx264 -pix_fmt yuv420p {VIDEO_NAME}")
#     # print(f"[OK] Vid√©o cr√©√©e : {VIDEO_NAME}")
#
# ############################################################
# # VERSION 2
#
# # === Traitement ===
# def main_alignement():
#     # global repertoire_sortie
#     IMG_DIR = repertoire_sortie
#     OUTPUT_DIR = IMG_DIR + "-alignes"
#
#     os.makedirs(OUTPUT_DIR, exist_ok=True)
#
#     files = sorted(glob.glob(os.path.join(IMG_DIR, "*.jpg")))
#     if not files:
#         raise SystemExit(f"Aucune image trouv√©e dans {IMG_DIR}")
#
#     # === 1. Calcul de l‚Äôimage de r√©f√©rence moyenne ===
#     print(f"[INFO] Calcul de l‚Äôimage moyenne √† partir des {min(N_AVG, len(files))} premi√®res images‚Ä¶")
#     subset = files[:N_AVG]
#     imgs = []
#     for f in subset:
#         im = cv2.imread(f).astype(np.float32)
#         imgs.append(im)
#     avg_ref = np.mean(imgs, axis=0).astype(np.uint8)
#     ref_gray = cv2.cvtColor(avg_ref, cv2.COLOR_BGR2GRAY)
#
#     # Sauvegarde optionnelle pour v√©rifier la r√©f√©rence
#     cv2.imwrite(os.path.join(OUTPUT_DIR, "_reference_average.jpg"), avg_ref)
#
#     # === 2. Fonction d‚Äôalignement (inchang√©e sauf ref pass√©e en param√®tre) ===
#     def align_images(im, im_ref_gray):
#         im1_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)
#         orb = cv2.ORB_create(MAX_FEATURES)
#         kp1, des1 = orb.detectAndCompute(im1_gray, None)
#         kp2, des2 = orb.detectAndCompute(im_ref_gray, None)
#
#         if des1 is None or des2 is None or len(kp1) < 4 or len(kp2) < 4:
#             return im.copy(), np.eye(3, dtype=np.float32)
#
#         bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=False)
#         knn_matches = bf.knnMatch(des1, des2, k=2)
#         good_matches = []
#         for m_n in knn_matches:
#             if len(m_n) != 2:
#                 continue
#             m, n = m_n
#             if m.distance < RATIO_TEST * n.distance:
#                 good_matches.append(m)
#
#         if len(good_matches) >= MIN_MATCH_COUNT:
#             pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])
#             pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])
#             H, mask = cv2.findHomography(pts1, pts2, cv2.RANSAC, 5.0)
#             if H is not None:
#                 h, w = im_ref_gray.shape[:2]
#                 im1_reg = cv2.warpPerspective(im, H, (w, h))
#                 return im1_reg, H
#
#         # Fallback affine
#         if len(good_matches) >= 4:
#             pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches])
#             pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches])
#             M, inliers = cv2.estimateAffinePartial2D(pts1, pts2, method=cv2.RANSAC)
#             if M is not None:
#                 h, w = im_ref_gray.shape[:2]
#                 im1_reg = cv2.warpAffine(im, M, (w, h))
#                 H_aff = np.vstack([M, [0, 0, 1]])
#                 return im1_reg, H_aff
#
#         # Si rien ne marche
#         return im.copy(), np.eye(3, dtype=np.float32)
#
#     # === 3. Alignement de toutes les images sur l‚Äôimage moyenne ===
#     print(f"[INFO] Alignement de {len(files)} images sur la r√©f√©rence moyenne‚Ä¶")
#     aligned_images = []
#     for f in tqdm(files, desc="Alignement"):
#         im = cv2.imread(f)
#         aligned, _ = align_images(im, ref_gray)
#         aligned_images.append((f, aligned))
#
#     # === 4. Calcul du recadrage commun ===
#     print("[INFO] Calcul du cadrage commun (zone non noire)‚Ä¶")
#     masks = [(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) > 0) for _, img in aligned_images]
#     common_mask = np.logical_and.reduce(masks).astype(np.uint8)
#     ys, xs = np.where(common_mask)
#     if ys.size == 0 or xs.size == 0:
#         raise SystemExit("Intersection vide ‚Äî les images sont trop d√©cal√©es apr√®s alignement.")
#     ymin, ymax, xmin, xmax = ys.min(), ys.max(), xs.min(), xs.max()
#
#     # === 5. Sauvegarde des images align√©es ===
#     print("[INFO] Sauvegarde des images align√©es‚Ä¶")
#     for orig_path, img in aligned_images:
#         filename = os.path.basename(orig_path)
#         cropped = img[ymin:ymax+1, xmin:xmax+1]
#         outpath = os.path.join(OUTPUT_DIR, filename)
#         cv2.imwrite(outpath, cropped)

############################################################
# VERSION 3

def reprojection_error(H, src_pts, dst_pts, affine=False):
    if affine:
        # src_pts: Nx2
        src_pts_h = np.hstack([src_pts, np.ones((len(src_pts), 1))])
        pred = (H @ src_pts_h.T).T  # Nx2
    else:
        src_pts_h = np.hstack([src_pts, np.ones((len(src_pts), 1))])
        pred_h = (H @ src_pts_h.T).T  # Nx3
        pred = pred_h[:, :2] / pred_h[:, 2:3]

    err = np.linalg.norm(pred - dst_pts, axis=1)
    return np.median(err)  # ou np.mean(err)



def ajouter_date_image(chemin_image):
    # --- 1. Extraire le nom de fichier sans extension ---
    nom_fichier = os.path.basename(chemin_image)

    # --- 2. Trouver la date au format yyyy-mm-dd ---
    match = re.search(r"\d{4}-\d{2}-\d{2}", nom_fichier)
    if not match:
        print("Aucune date trouv√©e dans le nom de fichier :", nom_fichier)
        return
    date_str = match.group(0)

   # --- 3. Charger l‚Äôimage et forcer RGBA ---
    img = Image.open(chemin_image)
    if img.mode != "RGBA":
        img = img.convert("RGBA")

    # --- 4. Police monospace ---
    try:
        font = ImageFont.truetype("DejaVuSansMono.ttf", size=max(20, img.height // 25))
    except IOError:
        font = ImageFont.load_default()

    # --- 5. Mesure du texte ---
    draw_tmp = ImageDraw.Draw(img)
    bbox = draw_tmp.textbbox((0, 0), date_str, font=font)
    text_width = bbox[2] - bbox[0]
    text_height = bbox[3] - bbox[1]

    # --- 6. Position bas droite ---
    margin = 10
    x = img.width - text_width - margin
    y = img.height - text_height - margin

    # --- 7. Cr√©er calque overlay RGBA ---
    overlay = Image.new("RGBA", img.size, (0, 0, 0, 0))
    draw_overlay = ImageDraw.Draw(overlay)

    # Fond semi-transparent
    draw_overlay.rectangle(
        [(x - 5, y - 3), (x + text_width + 5, y + text_height + 3)],
        fill=(0, 0, 0, 150)
    )
    # Texte jaune vif
    draw_overlay.text((x, y), date_str, font=font, fill=(255, 255, 0, 255))

    # --- 8. Fusion des calques ---
    img_composite = Image.alpha_composite(img, overlay)

    # --- 9. Conversion finale en RGB pour JPEG ---
    img_final = img_composite.convert("RGB")
    # sortie = os.path.splitext(chemin_image)[0] + "_date.jpg"
    # On √©crase !
    sortie = chemin_image
    img_final.save(sortie, quality=95)
    print("‚úÖ Image enregistr√©e :", sortie)



# TODO: detect aberrations in case none of the 2 alignement methods are accurate enough

def align_images_3(base_img, img_to_align, fname, max_features=5000, good_match_percent=0.15):
    """Aligne img_to_align sur base_img via d√©tection de points cl√©s (ORB) et homographie."""
    # Convertir en niveaux de gris

    # im1_gray = cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY)
    # im2_gray = cv2.cvtColor(img_to_align, cv2.COLOR_BGR2GRAY)

    # Mieux ?
    im1_gray = cv2.equalizeHist(cv2.cvtColor(base_img, cv2.COLOR_BGR2GRAY))
    im2_gray = cv2.equalizeHist(cv2.cvtColor(img_to_align, cv2.COLOR_BGR2GRAY))

    # D√©tection des points cl√©s et descripteurs
    # BEGIN ORB
    # orb = cv2.ORB_create(max_features)
    # keypoints1, descriptors1 = orb.detectAndCompute(im1_gray, None)
    # keypoints2, descriptors2 = orb.detectAndCompute(im2_gray, None)
    # # Appariement des descripteurs
    # matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)
    # END ORB
    # BEGIN AKAZE
    # detector = cv2.AKAZE_create()  # ou cv2.SIFT_create()
    # keypoints1, descriptors1 = detector.detectAndCompute(im1_gray, None)
    # keypoints2, descriptors2 = detector.detectAndCompute(im2_gray, None)
    #
    # # Appariement des descripteurs
    # matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)
    # END AKAZE

    detector = cv2.SIFT_create()
    keypoints1, descriptors1 = detector.detectAndCompute(im1_gray, None)
    keypoints2, descriptors2 = detector.detectAndCompute(im2_gray, None)

    # Appariement des descripteurs
    matcher = cv2.DescriptorMatcher_create(cv2.DescriptorMatcher_FLANNBASED)

    # BEGIN SIMPLE COMPARISON
    # # matches = matcher.match(descriptors1, descriptors2, None)
    # matches = list(matcher.match(descriptors1, descriptors2))
    #
    # # Trier selon la qualit√© (distance)
    # matches.sort(key=lambda x: x.distance, reverse=False)
    #
    # # Garder les meilleures correspondances
    # num_good_matches = int(len(matches) * good_match_percent)
    # matches = matches[:num_good_matches]
    # END SIMPLE COMPARISON

    # Appariement avec knn
    potential_matches = matcher.knnMatch(descriptors1, descriptors2, k=2)

    matches = []
    for m, n in potential_matches:
        if m.distance < 0.75 * n.distance:
            matches.append(m)

    # Extraire les points correspondants
    points1 = np.zeros((len(matches), 2), dtype=np.float32)
    points2 = np.zeros((len(matches), 2), dtype=np.float32)
    for i, match in enumerate(matches):
        points1[i, :] = keypoints1[match.queryIdx].pt
        points2[i, :] = keypoints2[match.trainIdx].pt

    height, width, channels = base_img.shape

    # Calcul de la transformation par homographie
    h_homog, mask_h = cv2.findHomography(points2, points1, cv2.RANSAC)

    # Calcul de la transformation affine
    h_affine, mask_a = cv2.estimateAffinePartial2D(points2, points1, method=cv2.RANSAC)

    err_homog = reprojection_error(h_homog, points2, points1, affine=False)
    err_affine = reprojection_error(h_affine, points2, points1, affine=True)

    if err_affine < err_homog:
        use_affine = True
    else:
        use_affine = False

    # if h is None or np.linalg.cond(h) > 1e4:
    #     h, mask = cv2.estimateAffinePartial2D(points2, points1, method=cv2.RANSAC)
    #     if h is not None:
    #         print(f"‚ö†Ô∏è Homographie douteuse pour {fname}, backup vers translation.")
    #         aligned_image = cv2.warpAffine(img_to_align, h, (width, height))
    #     else:
    #         print(f"‚ö†Ô∏è Homographie et translation douteuses pour {fname}, copie non align√©e.")
    #         aligned_image = img_to_align.copy()
    # else:
    #     # Appliquer la transformation homographie
    #     aligned_image = cv2.warpPerspective(img_to_align, h, (width, height))

    h = h_affine

    if use_affine:
        # Appliquer la transformation affine
        aligned_image = cv2.warpAffine(img_to_align, h_affine, (width, height))
        h = h_affine
    else:
        # Appliquer la transformation homographie
        aligned_image = cv2.warpPerspective(img_to_align, h_homog, (width, height))
        h = h_homog
        print(f"‚ö†Ô∏è Meilleure homographie pour {fname}.")

    return aligned_image, h

def align_folder_3(input_dir, output_dir):
    os.makedirs(output_dir, exist_ok=True)
    filenames = sorted([
        f for f in os.listdir(input_dir)
        if f.lower().endswith((".jpg", ".jpeg", ".png", ".tif"))
    ])

    if not filenames:
        print("Aucune image trouv√©e dans", input_dir)
        return

    # Image de r√©f√©rence
    ref_path = os.path.join(input_dir, filenames[0])
    ref_img = cv2.imread(ref_path)
    if ref_img is None:
        raise ValueError(f"Impossible de lire l'image de r√©f√©rence : {ref_path}")

    print(f"Image de r√©f√©rence : {filenames[0]}")

    # Sauvegarder l'image de r√©f√©rence telle quelle
    # TODO: mieux de d'abord cr√©er l'image puis ajouter le texte, et enfin l'exporter dans un fichier
    cv2.imwrite(os.path.join(output_dir, filenames[0]), ref_img)
    ajouter_date_image(os.path.join(output_dir, filenames[0]))

    # Aligner les autres
    for fname in tqdm(filenames[1:], desc="Alignement des images"):
        path = os.path.join(input_dir, fname)
        img = cv2.imread(path)
        if img is None:
            print(f"‚ö†Ô∏è  Impossible de lire {fname}, ignor√©e.")
            continue
        aligned, _ = align_images_3(ref_img, img, fname)
        # TODO: mieux de d'abord cr√©er l'image puis ajouter le texte, et enfin l'exporter dans un fichier
        cv2.imwrite(os.path.join(output_dir, fname), aligned)
        ajouter_date_image(os.path.join(output_dir, fname))

    print(f"\n‚úÖ Toutes les images ont √©t√© align√©es dans : {output_dir}")

# def main_alignement_3(repertoire_sortie_exif, repertoire_sortie_exif_aligne):
#     # import argparse
#     # parser = argparse.ArgumentParser(description="Aligne les images d'un dossier pour timelapse.")
#     # parser.add_argument("input_dir", help="Dossier contenant les images originales")
#     # parser.add_argument("output_dir", help="Dossier o√π sauvegarder les images align√©es")
#     # args = parser.parse_args()
#     # align_folder(args.input_dir, args.output_dir)
#     align_folder_3(repertoire_sortie_exif, repertoire_sortie_exif_aligne)

############################################################
# CONVERSION TO VIDEO

def photos_to_video_ffmpeg(images_dir, output_file, fps=1):
    print(f"Conversion des photos dans le r√©pertoire '{images_dir}'‚Ä¶")
    # V√©rifie la pr√©sence du dossier
    if not os.path.isdir(images_dir):
        print("‚ùå Le dossier sp√©cifi√© n'existe pas :", images_dir)
        sys.exit(1)

    # V√©rifie que ffmpeg est install√©
    if subprocess.call(["which", "ffmpeg"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL) != 0:
        print("‚ùå ffmpeg n'est pas install√©. Installez-le avec :")
        print("   sudo apt install ffmpeg")
        sys.exit(1)

    # Cr√©e une liste d‚Äôimages tri√©e (pour garantir l‚Äôordre)
    images = sorted([
        f for f in os.listdir(images_dir)
        if f.lower().endswith((".jpg", ".jpeg", ".png", ".bmp"))
    ])

    if not images:
        print("‚ùå Aucune image trouv√©e dans le dossier :", images_dir)
        sys.exit(1)

    # Cr√©e un fichier temporaire listant les images pour ffmpeg
    list_file = os.path.join("images.txt")
    with open(list_file, "w") as f:
        for img in images:
            f.write(f"file '{os.path.join(images_dir, img)}'\n")
            # f.write("duration 1\n") # NOTE: incompatible with `-r fps`
        # derni√®re image r√©p√©t√©e
        f.write(f"file '{os.path.join(images_dir, images[-1])}'\n")

    print("Fichier temporaire : " + list_file)

    cmd = [
        "ffmpeg",
        "-y",
        "-f", "concat",
        "-safe", "0",
        "-i", list_file,
        "-r", str(fps),
        "-pix_fmt", "yuv420p",
        output_file
    ]

    print(f"üéûÔ∏è Cr√©ation de la vid√©o '{output_file}' √† {fps} fps‚Ä¶")
    subprocess.run(cmd, check=True)
    os.remove(list_file)

    print(f"‚úÖ Vid√©o cr√©√©e avec succ√®s : {output_file}")

############################################################
# MAIN

if __name__ == "__main__":
    # V√©rification des arguments
    if len(sys.argv) < 2:
        print("Usage : python script.py <repertoire_entree> [prefixe] [repertoire_sortie]")
        sys.exit(1)

    repertoire_entree = sys.argv[1]
    prefixe = sys.argv[2] if len(sys.argv) >= 3 else "exif"

    repertoire_sortie_exif = sys.argv[3] if len(sys.argv) >= 4 else repertoire_entree.rstrip("/\\") + "-exif"
    repertoire_sortie_exif_aligne = repertoire_sortie_exif + "-alignes"


    if not os.path.isdir(repertoire_entree):
        print(f"Erreur : le r√©pertoire d‚Äôentr√©e '{repertoire_entree}' n‚Äôexiste pas.")
        sys.exit(1)

    print("\n=== Entr√©es ===")
    print(f"R√©pertoire source                    : {repertoire_entree}")
    print(f"Pr√©fixe                              : {prefixe}")
    print(f"R√©pertoire de sortie EXIF            : {repertoire_sortie_exif}")
    print(f"R√©pertoire de sortie EXIF alignement : {repertoire_sortie_exif_aligne}")

    os.makedirs(repertoire_sortie_exif, exist_ok=True)


    main_renommage(repertoire_entree, repertoire_sortie_exif)
        # main_alignement_old()
        # main_alignement()
    align_folder_3(repertoire_sortie_exif, repertoire_sortie_exif_aligne)
    photos_to_video_ffmpeg(repertoire_sortie_exif_aligne, VIDEO_NAME, FPS)

print("Done! :-)")
